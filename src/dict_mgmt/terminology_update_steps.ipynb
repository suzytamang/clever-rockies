{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following details out the steps taken to update the `dict.txt` file per case [Update dict.txt - remove xylazine terms](https://github.com/suzytamang/clever-rockies/issues/19).\n",
    "\n",
    "This will treat each modification as a separate and distinct series of actions (deletes), which will be used in turn to inform case [Support Feature: Renumbering and Validation Script](https://github.com/suzytamang/clever-rockies/issues/22)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# dataclass to hold terminology entry\n",
    "\n",
    "\n",
    "from abc import ABC\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from typing import Callable, List\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "from tabulate import tabulate\n",
    "from typing import Self\n",
    "from typing import Literal\n",
    "from typing import cast\n",
    "import functools\n",
    "from static_frame.core.frame import Frame\n",
    "from typing import List\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option(\"display.max_columns\", 20)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_seq_items\", 2000)\n",
    "\n",
    "IGNORE_VALIDATION_ERRORS = True\n",
    "\n",
    "\n",
    "class FrameHelper:\n",
    "\n",
    "    @staticmethod\n",
    "    def show(title: str, df: pd.DataFrame):\n",
    "        print(title)\n",
    "        print(tabulate(df, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "class ColumnLabels(ABC):\n",
    "\n",
    "    @classmethod\n",
    "    def all_values(cls):\n",
    "        return [\n",
    "            val for key, val in vars(cls).items() if not key.startswith(\"_\")\n",
    "        ]\n",
    "\n",
    "\n",
    "class HashLabels(ColumnLabels):\n",
    "    TERM_LABEL = \"term\"\n",
    "    SUBCLASS_LABEL = \"subclass_name\"\n",
    "    CLASS_LABEL = \"class_name\"\n",
    "\n",
    "\n",
    "class TermLabels(HashLabels):\n",
    "    ID_LABEL = \"id\"\n",
    "\n",
    "\n",
    "class NumberingDetails(ColumnLabels):\n",
    "    ID_CHUNK_LABEL = \"id_chunk\"\n",
    "    HASH_LABEL = \"hash_code\"\n",
    "\n",
    "\n",
    "class ValidationFlags(ColumnLabels):\n",
    "    IS_VALID_TERM_LABEL = \"is_valid_term\"\n",
    "    HAS_DUPLICATE_ID_LABEL = \"has_duplicate_id\"\n",
    "    DUPLICATE_TERM_CLASS_SUBCLASS_LABEL = \"duplicate_term_class_subclass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class IResetChanged(ABC):\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class ISetChanged(ABC):\n",
    "\n",
    "    def set_changed(self):\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def is_changed(self) -> bool:\n",
    "        pass\n",
    "\n",
    "\n",
    "class ChangedFlag(ISetChanged, IResetChanged):\n",
    "    \"\"\"Class to manage changed flag; controls access to only set as changed\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._is_changed = False\n",
    "\n",
    "    def set_changed(self):\n",
    "        self._is_changed = True\n",
    "    \n",
    "    @property\n",
    "    def is_changed(self) -> bool:\n",
    "        return self._is_changed\n",
    "\n",
    "    def reset(self):\n",
    "        self._is_changed = False\n",
    "\n",
    "    @property\n",
    "    def is_changed(self) -> bool:\n",
    "        return self._is_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Term:\n",
    "    id: int\n",
    "    term: str\n",
    "    subclass_name: str\n",
    "    class_name: str\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_hash_key(row: Union[pd.Series, 'Term']):\n",
    "        if isinstance(row, Term):\n",
    "            term = row.term\n",
    "            class_val = row.class_name\n",
    "            subclass_val = row.subclass_name\n",
    "        else:\n",
    "            term = row[HashLabels.TERM_LABEL]\n",
    "            class_val = row[HashLabels.CLASS_LABEL]\n",
    "            subclass_val = row[HashLabels.SUBCLASS_LABEL]\n",
    "        return hash(f\"{term}_{class_val}_{subclass_val}\")\n",
    "\n",
    "    def hash_key(self):\n",
    "        return Term.calc_hash_key(self)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.hash_key()\n",
    "\n",
    "    @staticmethod\n",
    "    def deserialize(term_string: str) -> \"Term\":\n",
    "        term_pieces = term_string.split(\"|\")\n",
    "        return Term(\n",
    "            id=int(term_pieces[0]),\n",
    "            term=term_pieces[1],\n",
    "            subclass_name=term_pieces[2],\n",
    "            class_name=term_pieces[3],\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def deserialize_terms(term_strings: List[str]) -> List[\"Term\"]:\n",
    "        return [Term.deserialize(term_string) for term_string in term_strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# Terminology Validator\n",
    "class TermValidator:\n",
    "\n",
    "    def __init__(self, *rules: Callable[[Term], bool]) -> None:\n",
    "\n",
    "        rules = list(rules)\n",
    "\n",
    "        # if no rules provided, then default to asserting term is valid\n",
    "\n",
    "        if len(rules) == 0:\n",
    "\n",
    "            rules.append(TermValidator.noop)\n",
    "\n",
    "        self._rules = rules\n",
    "\n",
    "\n",
    "    def __call__(self, term: Term) -> bool:\n",
    "\n",
    "        is_valid = all(is_valid(term) for is_valid in self._rules)\n",
    "\n",
    "        return is_valid\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    def noop(x) -> bool:\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# Terminology Validator\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DuplicateCheckResults:\n",
    "    duplicates_found: bool\n",
    "    strategy_name: str\n",
    "    labels_to_check: List[str]\n",
    "    flag_label: str\n",
    "    duplicate_entries: pd.DataFrame\n",
    "\n",
    "\n",
    "class DuplicateCheckingStrategy(ABC):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        strategy_name: str,\n",
    "        labels_to_check: str | List[str],\n",
    "        flag_label: str,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self._strategy_name: str = strategy_name\n",
    "        if isinstance(labels_to_check, str):\n",
    "            labels_to_check = [labels_to_check]\n",
    "\n",
    "        self._labels_to_check: List[str] = labels_to_check\n",
    "        self._flag_label: str = flag_label\n",
    "\n",
    "    def __call__(self, terms_df: pd.DataFrame) -> DuplicateCheckResults:\n",
    "        return self.duplicate_check(\n",
    "            terms_df, self._labels_to_check, self._flag_label\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def strategy_name(self):\n",
    "        return self._strategy_name\n",
    "\n",
    "    def duplicate_check(\n",
    "        self,\n",
    "        terms_df: pd.DataFrame,\n",
    "        labels_to_check: List[str],\n",
    "        flag_label: str,\n",
    "    ) -> DuplicateCheckResults:\n",
    "        \"\"\"Check to see if duplicates exist for a vector of columns\n",
    "\n",
    "        Args:\n",
    "            labels_to_check (List[str]): vector of columns to check\n",
    "            flag_label (str): label to add to dataframe for this flag\n",
    "\n",
    "        Returns:\n",
    "            bool: _description_\n",
    "        \"\"\"\n",
    "        duplicate_mask: pd.Series = terms_df[labels_to_check].duplicated()\n",
    "        terms_df[flag_label] = duplicate_mask\n",
    "        return DuplicateCheckResults(\n",
    "            duplicates_found=any(duplicate_mask),\n",
    "            strategy_name=self.strategy_name,\n",
    "            labels_to_check=labels_to_check,\n",
    "            flag_label=flag_label,\n",
    "            duplicate_entries=terms_df[terms_df[flag_label]],\n",
    "        )\n",
    "\n",
    "\n",
    "class DuplicateIdsCheckingStrategy(DuplicateCheckingStrategy):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\n",
    "            \"ids\", TermLabels.ID_LABEL, ValidationFlags.HAS_DUPLICATE_ID_LABEL\n",
    "        )\n",
    "\n",
    "\n",
    "class DuplicateTermsCheckingStrategy(DuplicateCheckingStrategy):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\n",
    "            \"term, class, subclass\",\n",
    "            [\n",
    "                TermLabels.TERM_LABEL,\n",
    "                TermLabels.CLASS_LABEL,\n",
    "                TermLabels.SUBCLASS_LABEL,\n",
    "            ],\n",
    "            ValidationFlags.DUPLICATE_TERM_CLASS_SUBCLASS_LABEL,\n",
    "        )\n",
    "\n",
    "\n",
    "class TerminologyValidator:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        term_validator: TermValidator,\n",
    "        *duplicate_checking: DuplicateCheckingStrategy,\n",
    "    ) -> None:\n",
    "        self._term_validator: TermValidator = term_validator\n",
    "        if duplicate_checking is None:\n",
    "            duplicate_checking = list()\n",
    "        else:\n",
    "            duplicate_checking = list(duplicate_checking)\n",
    "        self._duplicate_checking_strategies: List[\n",
    "            DuplicateCheckingStrategy\n",
    "        ] = duplicate_checking\n",
    "\n",
    "    def __call__(self, terms_df: pd.DataFrame) -> bool:\n",
    "\n",
    "        # validate each term with any term-level rules\n",
    "        terms_df[ValidationFlags.IS_VALID_TERM_LABEL] = terms_df.apply(\n",
    "            lambda term: self._term_validator(term), axis=1\n",
    "        )\n",
    "\n",
    "        terminology_is_valid = all(\n",
    "            terms_df[ValidationFlags.IS_VALID_TERM_LABEL]\n",
    "        )\n",
    "\n",
    "        for duplicate_check in self._duplicate_checking_strategies:\n",
    "            check_results: DuplicateCheckResults = duplicate_check(terms_df)\n",
    "\n",
    "            if check_results.duplicates_found:\n",
    "                terminology_is_valid = False\n",
    "                FrameHelper.show(\n",
    "                    f\"Duplicates found for {check_results.labels_to_check}\",\n",
    "                    check_results.duplicate_entries,\n",
    "                )\n",
    "\n",
    "        return terminology_is_valid\n",
    "\n",
    "    def does_term_exist(\n",
    "        self, terminology_df: pd.DataFrame, term: Term\n",
    "    ) -> bool:\n",
    "        \"\"\"Check to see if the term string exists\n",
    "\n",
    "        Args:\n",
    "            term (Term): _description_\n",
    "\n",
    "        Returns:\n",
    "            bool: _description_\n",
    "        \"\"\"\n",
    "        term_count = len(\n",
    "            terminology_df[terminology_df[TermLabels.TERM_LABEL] == term.term]\n",
    "        )\n",
    "        if term_count > 1:\n",
    "            print(\"More than one instance of term found: %s\", term)\n",
    "\n",
    "        return term_count == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "class TerminologyRenumberStrategy:\n",
    "    \"\"\"This strategy assumes the following:\n",
    "\n",
    "    - Terms ids are in 1k chunks\n",
    "    - Deleting a term drops the id and renumbers\n",
    "        all following terms up to the next 1k boundary\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ID_BLOCK_SIZE = 1000\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._monitor: IResetChanged | None = None\n",
    "\n",
    "    def __call__(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Iterates over each 1k block and compacts ids\n",
    "        to create a monotonically increasing id starting at\n",
    "        each 1k boundary.\n",
    "\n",
    "        Example:\n",
    "\n",
    "        | Original ID \t| Updated ID \t|\n",
    "        |-------------\t|------------\t|\n",
    "        | 1           \t| 1          \t|\n",
    "        | 2           \t| 2          \t|\n",
    "        | 10          \t| 3          \t|\n",
    "        | 100         \t| 4          \t|\n",
    "        | 1001        \t| 1000       \t|\n",
    "        | 1002        \t| 1001       \t|\n",
    "        | 1010        \t| 1002       \t|\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): current copy of the terminology\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: terminology with updated ids\n",
    "        \"\"\"\n",
    "\n",
    "        # Find all 1k chunks\n",
    "\n",
    "        df[NumberingDetails.ID_CHUNK_LABEL] = (\n",
    "            df[TermLabels.ID_LABEL] / TerminologyRenumberStrategy.ID_BLOCK_SIZE\n",
    "        ).apply(floor)\n",
    "\n",
    "        def reset_index(x: pd.DataFrame):\n",
    "            return x.reset_index(drop=True)\n",
    "\n",
    "        working_df: pd.DataFrame = (\n",
    "            df.groupby(by=NumberingDetails.ID_CHUNK_LABEL, as_index=False)[\n",
    "                df.columns.tolist()\n",
    "            ]\n",
    "            .apply(reset_index)\n",
    "            .reset_index()\n",
    "            .drop(labels=[\"level_0\", TermLabels.ID_LABEL], axis=1)\n",
    "            .rename({\"level_1\": TermLabels.ID_LABEL}, axis=1)\n",
    "        )\n",
    "\n",
    "        # Update id numbering for first chunk (id < 1000)\n",
    "        first_chunk_df: pd.DataFrame = working_df[\n",
    "            working_df[NumberingDetails.ID_CHUNK_LABEL] == 0\n",
    "        ].copy()\n",
    "        first_chunk_df[TermLabels.ID_LABEL] = (\n",
    "            first_chunk_df[TermLabels.ID_LABEL] + 1\n",
    "        )\n",
    "\n",
    "        # Update id numbering for chunks after the first one (id >= 1000)\n",
    "        remaining_chunks_df: pd.DataFrame = working_df[\n",
    "            working_df[NumberingDetails.ID_CHUNK_LABEL] > 0\n",
    "        ].copy()\n",
    "        remaining_chunks_df[TermLabels.ID_LABEL] = (\n",
    "            remaining_chunks_df[NumberingDetails.ID_CHUNK_LABEL]\n",
    "            * TerminologyRenumberStrategy.ID_BLOCK_SIZE\n",
    "            + remaining_chunks_df[TermLabels.ID_LABEL]\n",
    "        )\n",
    "\n",
    "        df = pd.concat([first_chunk_df, remaining_chunks_df])\n",
    "        # columns_to_drop = [NumberingDetails.ID_CHUNK_LABEL] + ValidationFlags.all_values()\n",
    "        # df = df.drop(\n",
    "        #     labels=columns_to_drop,\n",
    "        #     axis=1,\n",
    "        # )\n",
    "\n",
    "        self._monitor.reset()\n",
    "\n",
    "        return df\n",
    "\n",
    "    def set_monitor(self, monitor: IResetChanged):\n",
    "        self._monitor = monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# Primary management class for terminology actions\n",
    "\n",
    "\n",
    "class NotAllowed(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class TerminologyManager:\n",
    "    \"\"\"Manage additions, deletions, and updates to terminology\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        terms: pd.DataFrame | str,\n",
    "        terminology_validator: TerminologyValidator,\n",
    "        renumber_strategy: TerminologyRenumberStrategy,\n",
    "        ignore_validation_errors: bool = False,\n",
    "    ) -> None:\n",
    "        self._is_terminology_valid: bool = False\n",
    "        self._ignore_validation_errors: bool = ignore_validation_errors\n",
    "        change_monitor: ChangedFlag = ChangedFlag()\n",
    "        self._change_monitor: ISetChanged = change_monitor\n",
    "        if isinstance(terms, str):\n",
    "            terms: pd.DataFrame = pd.read_csv(\n",
    "                terms,\n",
    "                delimiter=\"|\",\n",
    "                names=[\n",
    "                    TermLabels.ID_LABEL,\n",
    "                    TermLabels.TERM_LABEL,\n",
    "                    TermLabels.SUBCLASS_LABEL,\n",
    "                    TermLabels.CLASS_LABEL,\n",
    "                ],\n",
    "            )\n",
    "\n",
    "        terms[NumberingDetails.HASH_LABEL] = terms.apply(\n",
    "            Term.calc_hash_key, axis=1\n",
    "        )\n",
    "\n",
    "        self._updated_terminology_df: pd.DataFrame = terms.copy()\n",
    "        self._original_terminology_df: pd.DataFrame = terms.copy()\n",
    "        self._terminology_validator: TerminologyValidator = (\n",
    "            terminology_validator\n",
    "        )\n",
    "        self._renumber_strategy: TerminologyRenumberStrategy = (\n",
    "            renumber_strategy\n",
    "        )\n",
    "        self._renumber_strategy.set_monitor(\n",
    "            cast(IResetChanged, self._change_monitor)\n",
    "        )\n",
    "\n",
    "        self._is_terminology_valid = self._terminology_validator(\n",
    "            self._original_terminology_df\n",
    "        )\n",
    "\n",
    "    def __enter__(self) -> Self:\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.renumber()\n",
    "\n",
    "    def renumber(self):\n",
    "        self._updated_terminology_df = self._renumber_strategy(\n",
    "            self._updated_terminology_df\n",
    "        )\n",
    "\n",
    "    def guard(condition):\n",
    "        def decorator(func):\n",
    "            @functools.wraps(func)\n",
    "            def wrapper(self, *args, **kwargs):\n",
    "                if not condition(self):\n",
    "                    raise NotAllowed(\n",
    "                        f\"Cannot call {func}; terminology is not valid\"\n",
    "                    )\n",
    "                return func(self, *args, **kwargs)\n",
    "\n",
    "            return wrapper\n",
    "\n",
    "        return decorator\n",
    "\n",
    "    @staticmethod\n",
    "    def as_readonly(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # return sf.Frame.from_pandas(df)\n",
    "        return df.copy()\n",
    "\n",
    "    def is_terminology_valid(self) -> bool:\n",
    "        return self._is_terminology_valid\n",
    "\n",
    "    def ignoring_errors(self) -> bool:\n",
    "        return self._ignore_validation_errors\n",
    "\n",
    "    def can_access_method(self) -> bool:\n",
    "        return self.is_terminology_valid() or self.ignoring_errors()\n",
    "\n",
    "    def find(self, source: Literal[\"original\"] | Literal[\"updated\"], **kwargs):\n",
    "        \"\"\"Search for entries in the original or updated terminology\n",
    "\n",
    "        Args:\n",
    "            source (Literal[&quot;original&quot;] | Literal[&quot;updated&quot;]): which dataset to pull from\n",
    "            **kwargs\n",
    "                ids (List[str]): list of ids\n",
    "                hash_codes (List[str]): list of hash codes for terms\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        df: pd.DataFrame\n",
    "\n",
    "        if source == \"original\":\n",
    "            df = self.get_original_terminology()\n",
    "        else:\n",
    "            df = self.get_updated_terminology()\n",
    "\n",
    "        search_column: str\n",
    "        search_key: str\n",
    "        search_terms: List\n",
    "\n",
    "        if \"ids\" in kwargs:\n",
    "            search_column = TermLabels.ID_LABEL\n",
    "            search_key = \"ids\"\n",
    "        elif \"hash_codes\" in kwargs:\n",
    "            search_column = NumberingDetails.HASH_LABEL\n",
    "            search_key = \"hash_codes\"\n",
    "\n",
    "        search_terms = kwargs.get(search_key)\n",
    "        if isinstance(search_terms, List) is False:\n",
    "            search_terms = [search_terms]\n",
    "\n",
    "        return df[df[search_column].isin(search_terms)]\n",
    "\n",
    "    def get_original_terminology(self) -> pd.DataFrame:\n",
    "        \"\"\"Return a copy of the original terminology\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: _description_\n",
    "        \"\"\"\n",
    "        return TerminologyManager.as_readonly(self._original_terminology_df)\n",
    "\n",
    "    def get_updated_terminology(self) -> pd.DataFrame:\n",
    "        \"\"\"Return the updated terminology, renumbering if a change was made\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: _description_\n",
    "        \"\"\"\n",
    "        if self._change_monitor.is_changed is True:\n",
    "            self.renumber()\n",
    "\n",
    "        return TerminologyManager.as_readonly(self._updated_terminology_df)\n",
    "\n",
    "    @guard(can_access_method)\n",
    "    def delete_term(self, term: Term) -> Self | None:\n",
    "        \"\"\"Remove a term from the terminology\n",
    "\n",
    "        Args:\n",
    "            term (Term): Delete a term from the terminology\n",
    "        \"\"\"\n",
    "        if (\n",
    "            self._terminology_validator.does_term_exist(\n",
    "                self._updated_terminology_df, term\n",
    "            )\n",
    "            is False\n",
    "        ):\n",
    "            print(\"Term %s does not exist\")\n",
    "            return\n",
    "        df: pd.DataFrame = self._updated_terminology_df\n",
    "\n",
    "        term_mask: pd.Series = (\n",
    "            df[NumberingDetails.HASH_LABEL] == term.hash_key()\n",
    "        )\n",
    "\n",
    "        if not any(term_mask):\n",
    "            raise Exception(\"Could not locate term in dict: %s\", str(term))\n",
    "\n",
    "        if len(df[term_mask]) > 1:\n",
    "            raise Exception(\n",
    "                \"Found more than one instance of term: %s\", str(term)\n",
    "            )\n",
    "\n",
    "        self._updated_terminology_df = df.loc[\n",
    "            ~term_mask, :\n",
    "        ]  # everything but the selected term\n",
    "        self._change_monitor.set_changed()\n",
    "        return self\n",
    "\n",
    "    @guard(can_access_method)\n",
    "    def add_term(self, term: Term) -> Self | None:\n",
    "        raise NotImplementedError(\"add_term\")\n",
    "        self._change_monitor.set_changed()\n",
    "        return self\n",
    "\n",
    "    @guard(can_access_method)\n",
    "    def update_term(self, term: Term) -> Self | None:\n",
    "        raise NotImplementedError(\"update_term\")\n",
    "        self._change_monitor.set_changed()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load terminology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates found for ['term', 'class_name', 'subclass_name']\n",
      "+-------+--------+-----------------+--------------+----------------------+-----------------+--------------------+---------------------------------+\n",
      "|    id | term   | subclass_name   | class_name   |            hash_code | is_valid_term   | has_duplicate_id   | duplicate_term_class_subclass   |\n",
      "|-------+--------+-----------------+--------------+----------------------+-----------------+--------------------+---------------------------------|\n",
      "| 19004 | basdai | FSDA            | assessment   | -4489148185848859167 | True            | False              | True                            |\n",
      "+-------+--------+-----------------+--------------+----------------------+-----------------+--------------------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "terminology_manager = TerminologyManager(\n",
    "    r\"..\\..\\res\\dicts\\dict.txt\",\n",
    "    terminology_validator=TerminologyValidator(\n",
    "        TermValidator(),\n",
    "        DuplicateIdsCheckingStrategy(),\n",
    "        DuplicateTermsCheckingStrategy(),\n",
    "    ),\n",
    "    renumber_strategy=TerminologyRenumberStrategy(),\n",
    "    ignore_validation_errors=IGNORE_VALIDATION_ERRORS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms which will be deleted\n",
      "+------+------------+-----------------+--------------+----------------------+-----------------+--------------------+---------------------------------+\n",
      "|   id | term       | subclass_name   | class_name   |            hash_code | is_valid_term   | has_duplicate_id   | duplicate_term_class_subclass   |\n",
      "|------+------------+-----------------+--------------+----------------------+-----------------+--------------------+---------------------------------|\n",
      "| 3001 | tranq      | XYLA            | drug         | -1802980043639505019 | True            | False              | False                           |\n",
      "| 3002 | tranq dope | XYLA            | drug         | -5111535385192017806 | True            | False              | False                           |\n",
      "| 3003 | zylazine   | XYLA            | drug         |  8072201324078923795 | True            | False              | False                           |\n",
      "+------+------------+-----------------+--------------+----------------------+-----------------+--------------------+---------------------------------+\n",
      "\n",
      "Window of terms to observe including surrounding terms\n",
      "+------+-----------------------------------+-----------------+--------------+----------------------+-----------------+--------------------+---------------------------------+\n",
      "|   id | term                              | subclass_name   | class_name   |            hash_code | is_valid_term   | has_duplicate_id   | duplicate_term_class_subclass   |\n",
      "|------+-----------------------------------+-----------------+--------------+----------------------+-----------------+--------------------+---------------------------------|\n",
      "| 3000 | xylazine                          | XYLA            | drug         |  5312780436728734500 | True            | False              | False                           |\n",
      "| 3001 | tranq                             | XYLA            | drug         | -1802980043639505019 | True            | False              | False                           |\n",
      "| 3002 | tranq dope                        | XYLA            | drug         | -5111535385192017806 | True            | False              | False                           |\n",
      "| 3003 | zylazine                          | XYLA            | drug         |  8072201324078923795 | True            | False              | False                           |\n",
      "| 4000 | for controlled substances outside | PDMP            | response1    | -2068336252037976051 | True            | False              | False                           |\n",
      "+------+-----------------------------------+-----------------+--------------+----------------------+-----------------+--------------------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if terminology_manager.is_terminology_valid():\n",
    "search_windows_ids = list(range(3000, 4001))\n",
    "\n",
    "original_df: pd.DataFrame = terminology_manager.find(\n",
    "    ids=search_windows_ids, source=\"original\"\n",
    ")\n",
    "\n",
    "window_hash_codes = original_df[NumberingDetails.HASH_LABEL].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "terms: List[Term] = Term.deserialize_terms(\n",
    "    [\n",
    "        \"3001|tranq|XYLA|drug\",\n",
    "        \"3002|tranq dope|XYLA|drug\",\n",
    "        \"3003|zylazine|XYLA|drug\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "FrameHelper.show(\n",
    "    \"Terms which will be deleted\",\n",
    "    original_df[original_df[NumberingDetails.HASH_LABEL].isin([x.hash_key() for x in terms])]\n",
    ")\n",
    "\n",
    "FrameHelper.show(\n",
    "    \"Window of terms to observe including surrounding terms\",\n",
    "    original_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing subset updated after deletion of \"tranq\", \"XYLA\", \"drug\"\n",
      "+------+-----------------------------------+-----------------+--------------+----------------------+------------+\n",
      "|   id | term                              | subclass_name   | class_name   |            hash_code |   id_chunk |\n",
      "|------+-----------------------------------+-----------------+--------------+----------------------+------------|\n",
      "| 3000 | xylazine                          | XYLA            | drug         |  5312780436728734500 |          3 |\n",
      "| 3001 | tranq dope                        | XYLA            | drug         | -5111535385192017806 |          3 |\n",
      "| 3002 | zylazine                          | XYLA            | drug         |  8072201324078923795 |          3 |\n",
      "| 4000 | for controlled substances outside | PDMP            | response1    | -2068336252037976051 |          4 |\n",
      "+------+-----------------------------------+-----------------+--------------+----------------------+------------+\n",
      "\n",
      "Showing subset updated after deletion of \"tranq dope\", \"XYLA\", \"drug\"\n",
      "+------+-----------------------------------+-----------------+--------------+----------------------+------------+\n",
      "|   id | term                              | subclass_name   | class_name   |            hash_code |   id_chunk |\n",
      "|------+-----------------------------------+-----------------+--------------+----------------------+------------|\n",
      "| 3000 | xylazine                          | XYLA            | drug         |  5312780436728734500 |          3 |\n",
      "| 3001 | zylazine                          | XYLA            | drug         |  8072201324078923795 |          3 |\n",
      "| 4000 | for controlled substances outside | PDMP            | response1    | -2068336252037976051 |          4 |\n",
      "+------+-----------------------------------+-----------------+--------------+----------------------+------------+\n",
      "\n",
      "Showing subset updated after deletion of \"zylazine\", \"XYLA\", \"drug\"\n",
      "+------+-----------------------------------+-----------------+--------------+----------------------+------------+\n",
      "|   id | term                              | subclass_name   | class_name   |            hash_code |   id_chunk |\n",
      "|------+-----------------------------------+-----------------+--------------+----------------------+------------|\n",
      "| 3000 | xylazine                          | XYLA            | drug         |  5312780436728734500 |          3 |\n",
      "| 4000 | for controlled substances outside | PDMP            | response1    | -2068336252037976051 |          4 |\n",
      "+------+-----------------------------------+-----------------+--------------+----------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for term in terms:\n",
    "    \n",
    "    terminology_manager.delete_term(term)\n",
    "\n",
    "    updated_terminology_df = terminology_manager.find(hash_codes=window_hash_codes, source=\"updated\")\n",
    "    FrameHelper.show(\n",
    "        f'Showing subset updated after deletion of \"{term.term}\", \"{term.subclass_name}\", \"{term.class_name}\"',\n",
    "        updated_terminology_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get renumbered terminology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original terminology\n",
      "+------+---------+-----------------+--------------+----------------------+-----------------+--------------------+---------------------------------+\n",
      "|   id | term    | subclass_name   | class_name   |            hash_code | is_valid_term   | has_duplicate_id   | duplicate_term_class_subclass   |\n",
      "|------+---------+-----------------+--------------+----------------------+-----------------+--------------------+---------------------------------|\n",
      "|    1 | .       | DOT             | boundry      |   813019279694751451 | True            | False              | False                           |\n",
      "|    2 | ;       | DOT             | boundry      | -9192791342654108884 | True            | False              | False                           |\n",
      "|   10 | old     | HX              | modifier     |  1468161944162412334 | True            | False              | False                           |\n",
      "|   11 | hx      | HX              | modifier     |  5978150931564632931 | True            | False              | False                           |\n",
      "|   12 | h/o     | HX              | modifier     |  5349277412124454252 | True            | False              | False                           |\n",
      "|   13 | history | HX              | modifier     | -8066306272500136305 | True            | False              | False                           |\n",
      "|   14 | prior   | HX              | modifier     | -9055999893804321326 | True            | False              | False                           |\n",
      "|   15 | ho      | HX              | modifier     | -5685116940519098420 | True            | False              | False                           |\n",
      "|   16 | past    | HX              | modifier     |  4745600730541628826 | True            | False              | False                           |\n",
      "|   17 | has had | HX              | modifier     |  6366697019170690086 | True            | False              | False                           |\n",
      "+------+---------+-----------------+--------------+----------------------+-----------------+--------------------+---------------------------------+\n",
      "\n",
      "Updated terminology with renumbered ids\n",
      "+------+---------+-----------------+--------------+----------------------+------------+\n",
      "|   id | term    | subclass_name   | class_name   |            hash_code |   id_chunk |\n",
      "|------+---------+-----------------+--------------+----------------------+------------|\n",
      "|    1 | .       | DOT             | boundry      |   813019279694751451 |          0 |\n",
      "|    2 | ;       | DOT             | boundry      | -9192791342654108884 |          0 |\n",
      "|    3 | old     | HX              | modifier     |  1468161944162412334 |          0 |\n",
      "|    4 | hx      | HX              | modifier     |  5978150931564632931 |          0 |\n",
      "|    5 | h/o     | HX              | modifier     |  5349277412124454252 |          0 |\n",
      "|    6 | history | HX              | modifier     | -8066306272500136305 |          0 |\n",
      "|    7 | prior   | HX              | modifier     | -9055999893804321326 |          0 |\n",
      "|    8 | ho      | HX              | modifier     | -5685116940519098420 |          0 |\n",
      "|    9 | past    | HX              | modifier     |  4745600730541628826 |          0 |\n",
      "|   10 | has had | HX              | modifier     |  6366697019170690086 |          0 |\n",
      "+------+---------+-----------------+--------------+----------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FrameHelper.show(\"Original terminology\", terminology_manager.get_original_terminology().head(10))\n",
    "\n",
    "updated_df: pd.DataFrame = terminology_manager.get_updated_terminology()\n",
    "FrameHelper.show(\"Updated terminology with renumbered ids\", updated_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
